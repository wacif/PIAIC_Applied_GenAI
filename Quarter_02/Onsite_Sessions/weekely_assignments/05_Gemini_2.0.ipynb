{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M1mblPXyBOk"
   },
   "source": [
    "# **Assignment 05:** Exploring Gemini 2.0 Video and Audio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3173,
     "status": "ok",
     "timestamp": 1735395568276,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "F9ohuK1NxNIC",
    "outputId": "3b8832c2-18a1-43cf-cdaa-4c2f3b37c05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.27.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.10.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.0dev,>=13.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2024.12.14)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1959,
     "status": "ok",
     "timestamp": 1735395573252,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "rG6fIiN_BWbW"
   },
   "outputs": [],
   "source": [
    "# API Key setup\n",
    "from google.colab import userdata\n",
    "import time\n",
    "api_key = userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2032,
     "status": "ok",
     "timestamp": 1735395577984,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "R8KM69_6J3JU"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1735397188446,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "Xo_JRgfT3lLp"
   },
   "outputs": [],
   "source": [
    "path = \"/content/test_video_1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11979,
     "status": "ok",
     "timestamp": 1735397208612,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "ht8jpsMiKVWc",
    "outputId": "d0306703-0e1d-4e7d-c1d2-5dfce61e0b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for video to be processed.\n",
      "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/rv9r1ujgn9gw\n"
     ]
    }
   ],
   "source": [
    "# Upload video .\n",
    "def upload_video(video_file_name):\n",
    "  video_file = client.files.upload(path=video_file_name)\n",
    "  while video_file.state == \"PROCESSING\":\n",
    "      print('Waiting for video to be processed.')\n",
    "      time.sleep(10)\n",
    "      video_file = client.files.get(name=video_file.name or \"\")\n",
    "\n",
    "  if video_file.state == \"FAILED\":\n",
    "    raise ValueError(video_file.state)\n",
    "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
    "\n",
    "  return video_file\n",
    "\n",
    "processed_video = upload_video(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "executionInfo": {
     "elapsed": 5914,
     "status": "ok",
     "timestamp": 1735397217979,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "Fu8FZb5q4W9q",
    "outputId": "a1ace749-2455-4759-bbc9-28c9840ca237"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "[\n",
       "    {\n",
       "        \"timecode\": \"00:00\",\n",
       "        \"caption\": \"A man with a beard, wearing a gray shirt and headphones, is looking towards the camera holding a white pen with black accents. He is sitting at a table with a floral patterned cloth.\"\n",
       "    },\n",
       "     {\n",
       "        \"timecode\": \"00:01\",\n",
       "         \"caption\": \"The man adjusts the microphone on his headphones and looks down at the pen he is holding. He says, “Hello, this is Wasif. I want to record this video to test the VN capabilities of Gemini 2.0 model and also the speech to text capability.”\"\n",
       "   },\n",
       "     {\n",
       "       \"timecode\": \"00:16\",\n",
       "        \"caption\": \"The man looks at the camera while holding a white pen and continues, “So here is I have a pen. and I have a jar of coffee.”\"\n",
       "    },\n",
       "    {\n",
       "        \"timecode\": \"00:23\",\n",
       "         \"caption\": \"The man looks down to place the pen and the jar of coffee down before taking out a notebook and pen. He states, “And now I write few things over a paper.” \"\n",
       "    },\n",
       "   {\n",
       "      \"timecode\": \"00:34\",\n",
       "      \"caption\": \"The man looks up and holds up a paper to the camera that reads ‘DATE’ written in black ink.\"\n",
       "    },\n",
       "  {\n",
       "        \"timecode\": \"00:38\",\n",
       "         \"caption\":\"The man looks down as he starts to draw on the paper with the black pen. \"\n",
       "      },\n",
       "    {\n",
       "      \"timecode\": \"00:46\",\n",
       "        \"caption\":\"The man looks up and holds up a paper to the camera that shows a simple drawing of a smiling face with large eyes. He states, “So here is my drawing.”\"\n",
       "    },\n",
       "      {\n",
       "        \"timecode\":\"00:50\",\n",
       "        \"caption\":\"The man puts down the paper and starts to draw another image while facing down. \"\n",
       "     },\n",
       "    {\n",
       "     \"timecode\":\"01:11\",\n",
       "       \"caption\": \"The man looks up and holds up a paper to the camera with a simple drawing of a house, sun, clouds, and birds. He states, “So here is another drawing.”\"\n",
       "   },\n",
       "    {\n",
       "         \"timecode\": \"01:14\",\n",
       "        \"caption\":\"The man puts down the paper and holds a pen in his hands while looking down.\"\n",
       "    }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the video / vision capabilities of the model\n",
    "from google.genai.types import Content, Part\n",
    "from IPython.display import Markdown\n",
    "\n",
    "prompt = \"\"\"For each scene in this video,\n",
    "            generate captions that describe the scene along with any spoken text placed in quotation marks.\n",
    "            Place each caption into an object with the timecode of the caption in the video.\n",
    "         \"\"\"\n",
    "\n",
    "video = processed_video\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=[\n",
    "        Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                Part.from_uri(\n",
    "                    file_uri=video.uri or \"\",\n",
    "                    mime_type=video.mime_type or \"\"),\n",
    "                ]),\n",
    "        prompt,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5936,
     "status": "ok",
     "timestamp": 1735397229094,
     "user": {
      "displayName": "Wasif Nawaz",
      "userId": "00958325330036337850"
     },
     "user_tz": -300
    },
    "id": "gNHd9DYItm0i",
    "outputId": "a21dc59a-bbfa-47b0-ed8c-a10cb0a78bf3"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "[\n",
       "  {\n",
       "    \"start\": \"0:00\",\n",
       "    \"end\": \"0:01\",\n",
       "    \"text\": \"Hello.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"0:01\",\n",
       "    \"end\": \"0:02\",\n",
       "    \"text\": \"This is Wasif.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"0:03\",\n",
       "    \"end\": \"0:15\",\n",
       "    \"text\": \"I want to record this video to test the VN capabilities of Gemini 2.0 model and also the speech to text capability.\"\n",
       "  },\n",
       "    {\n",
       "    \"start\": \"0:16\",\n",
       "    \"end\": \"0:21\",\n",
       "    \"text\": \"So here is I have a pen and I have a\"\n",
       "  },\n",
       "    {\n",
       "    \"start\": \"0:21\",\n",
       "    \"end\": \"0:23\",\n",
       "    \"text\": \"jar of coffee.\"\n",
       "  },\n",
       "    {\n",
       "    \"start\": \"0:24\",\n",
       "    \"end\": \"0:25\",\n",
       "    \"text\": \"And now\"\n",
       "  },\n",
       "    {\n",
       "    \"start\": \"0:25\",\n",
       "    \"end\": \"0:29\",\n",
       "    \"text\": \"I write few things over a paper.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"0:34\",\n",
       "    \"end\": \"0:37\",\n",
       "    \"text\": \"look at it this.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"0:38\",\n",
       "    \"end\": \"0:39\",\n",
       "    \"text\": \"And now\"\n",
       "  },\n",
       "    {\n",
       "    \"start\": \"0:39\",\n",
       "    \"end\": \"0:40\",\n",
       "    \"text\": \"I draw something.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"0:46\",\n",
       "    \"end\": \"0:49\",\n",
       "    \"text\": \"So here is my drawing.\"\n",
       "  },\n",
       "  {\n",
       "    \"start\": \"1:12\",\n",
       "    \"end\": \"1:13\",\n",
       "    \"text\": \"Here is another drawing.\"\n",
       "  }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the audio capability of the model\n",
    "prompt_1 = \"\"\"Extract and transcribe all spoken text with timestamp in json from the audio of the provided video. Ensure the transcription is accurate and clear.\"\"\"\n",
    "\n",
    "video = processed_video\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=[\n",
    "        Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                Part.from_uri(\n",
    "                    file_uri=video.uri or \"\",\n",
    "                    mime_type=video.mime_type or \"\"),\n",
    "                ]),\n",
    "        prompt_1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZk1v/TjXnRBI14aiv6gD9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
